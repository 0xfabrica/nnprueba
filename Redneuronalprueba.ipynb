{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Red Neuronal CNN con DataSet CIFAR-10"
      ],
      "metadata": {
        "id": "wJxfIm9Mnx40"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3Q4ip7UsjRMS"
      },
      "outputs": [],
      "source": [
        "#import tensorflow as tf\n",
        "#from tensorflow.keras import datasets, layers, models\n",
        "#import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wbwXWmMxjUpu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "00214876-a21c-4027-af72-f51c44c83911"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Cargar y preprocesar el conjunto de datos CIFAR-10\\n#(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\\n#train_images, test_images = train_images / 255.0, test_images / 255.0\\n#class_names = ['Avión', 'Coche', 'Pájaro', 'Gato', 'Ciervo', 'Perro', 'Rana', 'Caballo', 'Barco', 'Camión']\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "\"\"\"\n",
        "# Cargar y preprocesar el conjunto de datos CIFAR-10\n",
        "#(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "#train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "#class_names = ['Avión', 'Coche', 'Pájaro', 'Gato', 'Ciervo', 'Perro', 'Rana', 'Caballo', 'Barco', 'Camión']\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fiGxlDh2jYJy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "f473cd35-9959-4cef-aa82-41d69448600d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\\n\\n# Aumento de datos solo en el conjunto de entrenamiento\\ndatagen = ImageDataGenerator(\\n    rotation_range=15,       # Rotación aleatoria de imágenes hasta 15 grados\\n    width_shift_range=0.1,   # Desplazamiento horizontal aleatorio (fracción del ancho total)\\n    height_shift_range=0.1,  # Desplazamiento vertical aleatorio (fracción de la altura total)\\n    horizontal_flip=True,    # Volteo horizontal aleatorio\\n    # zoom_range=0.2,        # Zoom aleatorio (opcional, a veces puede ayudar, otras no)\\n    # fill_mode='nearest'    # Cómo rellenar píxeles nuevos tras transformaciones (opcional)\\n    )\\n\\ndatagen.fit(train_images) # Ajusta el generador a las imágenes de entrenamiento (calcula estadísticas internas si es necesario)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "\"\"\"\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Aumento de datos solo en el conjunto de entrenamiento\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,       # Rotación aleatoria de imágenes hasta 15 grados\n",
        "    width_shift_range=0.1,   # Desplazamiento horizontal aleatorio (fracción del ancho total)\n",
        "    height_shift_range=0.1,  # Desplazamiento vertical aleatorio (fracción de la altura total)\n",
        "    horizontal_flip=True,    # Volteo horizontal aleatorio\n",
        "    # zoom_range=0.2,        # Zoom aleatorio (opcional, a veces puede ayudar, otras no)\n",
        "    # fill_mode='nearest'    # Cómo rellenar píxeles nuevos tras transformaciones (opcional)\n",
        "    )\n",
        "\n",
        "datagen.fit(train_images) # Ajusta el generador a las imágenes de entrenamiento (calcula estadísticas internas si es necesario)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "K6X0nm6Gjo14",
        "outputId": "c7d2bf49-6405-4045-b251-59fe66b1d240"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Definir la arquitectura del modelo CNN - AÑADIDO Dropout\\nmodel = models.Sequential([\\n    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\\n    layers.MaxPooling2D((2, 2)),\\n    layers.Dropout(0.25), # Dropout después de la primera capa de pooling\\n\\n    layers.Conv2D(64, (3, 3), activation='relu'),\\n    layers.MaxPooling2D((2, 2)),\\n    layers.Dropout(0.25), # Dropout después de la segunda capa de pooling\\n\\n    layers.Conv2D(64, (3, 3), activation='relu'),\\n    layers.Flatten(),\\n    layers.Dropout(0.5),  # Dropout antes de la primera capa densa (valor más alto)\\n    layers.Dense(64, activation='relu'),\\n    layers.Dense(10)\\n])\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "\"\"\"\n",
        "# Definir la arquitectura del modelo CNN - AÑADIDO Dropout\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25), # Dropout después de la primera capa de pooling\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25), # Dropout después de la segunda capa de pooling\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dropout(0.5),  # Dropout antes de la primera capa densa (valor más alto)\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10)\n",
        "])\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nb6YIrX5jjaz"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Compilar y entrenar el modelo - MODIFICADO para usar el generador de datos\n",
        "#model.compile(optimizer='adam',\n",
        "#             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "uv98lUGejl7J",
        "outputId": "fea21870-9a06-4aa0-8b7a-bbdba07ec1dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Entrenar usando datagen.flow() en lugar de pasar directamente train_images y train_labels\\nhistory = model.fit(datagen.flow(train_images, train_labels, batch_size=32), # Flujo de datos aumentado\\n                          epochs=20, # Aumentamos el número de épocas para dar tiempo a aprender con más datos\\n                          validation_data=(test_images, test_labels))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "\"\"\"\n",
        "# Entrenar usando datagen.flow() en lugar de pasar directamente train_images y train_labels\n",
        "history = model.fit(datagen.flow(train_images, train_labels, batch_size=32), # Flujo de datos aumentado\n",
        "                          epochs=20, # Aumentamos el número de épocas para dar tiempo a aprender con más datos\n",
        "                          validation_data=(test_images, test_labels))\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DXw0GDaajul6"
      },
      "outputs": [],
      "source": [
        "# Visualizar el progreso del entrenamiento (opcional)\n",
        "#plt.plot(history.history['accuracy'], label='accuracy')\n",
        "#plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "#plt.xlabel('Epoch')\n",
        "#plt.ylabel('Accuracy')\n",
        "#plt.ylim([0.5, 1])\n",
        "#plt.legend(loc='lower right')\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vlRiPvX9eAd7"
      },
      "outputs": [],
      "source": [
        "# Hacer predicciones (opcional - código para predecir la primera imagen del conjunto de prueba está en el texto anterior)\n",
        "# probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
        "# predictions = probability_model.predict(test_images)\n",
        "# ... (código de predicción e visualización de la predicción para la primera imagen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "8y4eombNwXDy",
        "outputId": "9ddc3be7-5a40-4a3d-e39c-464c73480a43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nMODEL_SAVE_PATH = \\'/content/mymodel.keras\\' # Directorio donde se guardará el modelo\\nmodel.save(MODEL_SAVE_PATH)\\nprint(f\"Modelo guardado en formato SavedModel en: {MODEL_SAVE_PATH}\")\\n\\n# 2. Cargar el modelo guardado (para usarlo o seguir entrenando)\\nloaded_model = tf.keras.models.load_model(MODEL_SAVE_PATH)\\n\\n# Ahora \\'loaded_model\\' es un modelo Keras completamente funcional,\\n# puedes usarlo para predicciones, evaluación, o continuar entrenando.\\n\\n# Verificar que el modelo cargado funciona (opcional)\\ntest_loss, test_acc = loaded_model.evaluate(test_images,  test_labels, verbose=2)\\nprint(\\'\\nPrecisión del modelo cargado en datos de prueba:\\', test_acc)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "\"\"\"\n",
        "MODEL_SAVE_PATH = '/content/mymodel.keras' # Directorio donde se guardará el modelo\n",
        "model.save(MODEL_SAVE_PATH)\n",
        "print(f\"Modelo guardado en formato SavedModel en: {MODEL_SAVE_PATH}\")\n",
        "\n",
        "# 2. Cargar el modelo guardado (para usarlo o seguir entrenando)\n",
        "loaded_model = tf.keras.models.load_model(MODEL_SAVE_PATH)\n",
        "\n",
        "# Ahora 'loaded_model' es un modelo Keras completamente funcional,\n",
        "# puedes usarlo para predicciones, evaluación, o continuar entrenando.\n",
        "\n",
        "# Verificar que el modelo cargado funciona (opcional)\n",
        "test_loss, test_acc = loaded_model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print('\\nPrecisión del modelo cargado en datos de prueba:', test_acc)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Red Neuronal Convolucional CNN con Pytorch"
      ],
      "metadata": {
        "id": "0R05uk8urQ32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "gwTalLWlrUMu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Cargar y preparar el dataset CIFAR-10:\n",
        "\n",
        "PyTorch facilita mucho la carga de datasets comunes a través de torchvision.datasets.  También podemos definir transformaciones para preprocesar las imágenes (normalización, etc.).  Vamos a crear DataLoaders para el entrenamiento y la prueba."
      ],
      "metadata": {
        "id": "lZwBsFD7swCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformaciones para las imágenes (normalización estándar para CIFAR-10)\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),  # Convierte imágenes PIL a tensores de PyTorch\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # Normaliza los canales RGB\n",
        "\n",
        "# Dataset de entrenamiento CIFAR-10\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "# Dataset de prueba CIFAR-10\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiQHyq49rgcv",
        "outputId": "4abefb88-c8c0-4c17-bdd5-16a1e4764355"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:02<00:00, 84.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Definir la arquitectura de la CNN:\n",
        "\n",
        "En PyTorch, definimos las redes neuronales como clases que heredan de nn.Module.  Dentro de la clase, definimos las capas en el __init__ y la forma en que los datos fluyen a través de las capas en el método forward.\n",
        "\n"
      ],
      "metadata": {
        "id": "3jIFWT54sq8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Capas convolucionales:\n",
        "        # Conv2d(canales_entrada, canales_salida, tamaño_kernel)\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1) # 3 canales de entrada (RGB), 32 canales de salida, kernel 3x3 y padding\n",
        "        # Gracias al padding conserva el tamaño de salida (ej:5x5 entrada, 5x5 salida)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1) # 32 canales de entrada (salida de conv1), 64 canales de salida, kernel 5x5\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1) # Nueva capa convolucional en el constructor\n",
        "        self.pool = nn.MaxPool2d(2, 2)     # Capa de Max Pooling 2x2, reduce dimensionalidad de las caracteristicas extraídas por las capas convolucionales\n",
        "        # Capas totalmente conectadas (lineales):\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 512) # 16*5*5 = tamaño de la salida aplanada de conv2\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)      # 10 clases de salida (CIFAR-10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Función de paso hacia adelante: define cómo los datos fluyen por la red\n",
        "        x = self.pool(F.relu(self.conv1(x))) # conv1 -> ReLU -> pool\n",
        "        x = self.pool(F.relu(self.conv2(x))) # conv2 -> ReLU -> pool\n",
        "        x = self.pool(F.relu(self.conv3(x))) # Nueva capa en el Forward\n",
        "\n",
        "        x = torch.flatten(x, 1) # Aplanar la salida para las capas totalmente conectadas (aplanar desde la dimensión 1 en adelante)\n",
        "\n",
        "        x = F.relu(self.fc1(x))           # fc1 -> ReLU\n",
        "        x = F.relu(self.fc2(x))           # fc2 -> ReLU\n",
        "        x = self.fc3(x)                   # fc3 (capa de salida, no ReLU aquí típicamente en clasificación)\n",
        "        return x\n",
        "\n",
        "net = Net() # Crear una instancia de la red neuronal"
      ],
      "metadata": {
        "id": "IfAFAYwLsBVz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Definir la función de pérdida y el optimizador:\n",
        "\n",
        "Necesitamos definir cómo vamos a medir el \"error\" de nuestro modelo (función de pérdida) y cómo vamos a actualizar los pesos del modelo para reducir este error (optimizador).  Para clasificación multiclase, nn.CrossEntropyLoss es una opción común, y optim.SGD (descenso de gradiente estocástico) es un optimizador clásico."
      ],
      "metadata": {
        "id": "iFA10piosgLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss() # Función de pérdida: Cross Entropy Loss (común para clasificación multiclase)\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # Optimizador: SGD (Stochastic Gradient Descent)\n",
        "                                                                   # lr: learning rate (tasa de aprendizaje), momentum: para acelerar el descenso"
      ],
      "metadata": {
        "id": "z6LU0I0VsCQr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Entrenar la red:\n",
        "\n",
        "Ahora viene el ciclo de entrenamiento. Iteramos sobre los datos de entrenamiento (DataLoader), hacemos el paso hacia adelante (forward pass), calculamos la pérdida, hacemos el paso hacia atrás (backward pass) para calcular los gradientes, y actualizamos los pesos del modelo con el optimizador."
      ],
      "metadata": {
        "id": "ykqR8GHNsdpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(20):  # Loop sobre el dataset varias veces (épocas)\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0): # Loop sobre batches de datos\n",
        "        inputs, labels = data      # Obtener las imágenes y las etiquetas del batch\n",
        "        optimizer.zero_grad()       # Poner a cero los gradientes (importante en cada iteración)\n",
        "\n",
        "        outputs = net(inputs)       # Paso hacia adelante: obtener las predicciones del modelo\n",
        "        loss = criterion(outputs, labels) # Calcular la pérdida (diferencia entre predicciones y etiquetas reales)\n",
        "        loss.backward()             # Paso hacia atrás: calcular los gradientes\n",
        "        optimizer.step()            # Optimizar: actualizar los pesos del modelo usando los gradientes y el optimizador\n",
        "\n",
        "        running_loss += loss.item() # Acumular la pérdida para este batch\n",
        "        if i % 2000 == 1999:    # Imprimir cada 2000 batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIZCOv06sF_r",
        "outputId": "6436750b-0041-4324-abfe-13e21dbfbee4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 2.244\n",
            "[1,  4000] loss: 1.880\n",
            "[1,  6000] loss: 1.657\n",
            "[1,  8000] loss: 1.513\n",
            "[1, 10000] loss: 1.418\n",
            "[1, 12000] loss: 1.343\n",
            "[2,  2000] loss: 1.219\n",
            "[2,  4000] loss: 1.175\n",
            "[2,  6000] loss: 1.125\n",
            "[2,  8000] loss: 1.074\n",
            "[2, 10000] loss: 1.035\n",
            "[2, 12000] loss: 0.996\n",
            "[3,  2000] loss: 0.887\n",
            "[3,  4000] loss: 0.882\n",
            "[3,  6000] loss: 0.854\n",
            "[3,  8000] loss: 0.814\n",
            "[3, 10000] loss: 0.811\n",
            "[3, 12000] loss: 0.832\n",
            "[4,  2000] loss: 0.682\n",
            "[4,  4000] loss: 0.681\n",
            "[4,  6000] loss: 0.701\n",
            "[4,  8000] loss: 0.672\n",
            "[4, 10000] loss: 0.685\n",
            "[4, 12000] loss: 0.669\n",
            "[5,  2000] loss: 0.511\n",
            "[5,  4000] loss: 0.529\n",
            "[5,  6000] loss: 0.558\n",
            "[5,  8000] loss: 0.564\n",
            "[5, 10000] loss: 0.558\n",
            "[5, 12000] loss: 0.579\n",
            "[6,  2000] loss: 0.395\n",
            "[6,  4000] loss: 0.432\n",
            "[6,  6000] loss: 0.430\n",
            "[6,  8000] loss: 0.446\n",
            "[6, 10000] loss: 0.468\n",
            "[6, 12000] loss: 0.463\n",
            "[7,  2000] loss: 0.298\n",
            "[7,  4000] loss: 0.323\n",
            "[7,  6000] loss: 0.346\n",
            "[7,  8000] loss: 0.354\n",
            "[7, 10000] loss: 0.358\n",
            "[7, 12000] loss: 0.374\n",
            "[8,  2000] loss: 0.209\n",
            "[8,  4000] loss: 0.252\n",
            "[8,  6000] loss: 0.252\n",
            "[8,  8000] loss: 0.276\n",
            "[8, 10000] loss: 0.276\n",
            "[8, 12000] loss: 0.314\n",
            "[9,  2000] loss: 0.174\n",
            "[9,  4000] loss: 0.180\n",
            "[9,  6000] loss: 0.210\n",
            "[9,  8000] loss: 0.205\n",
            "[9, 10000] loss: 0.232\n",
            "[9, 12000] loss: 0.252\n",
            "[10,  2000] loss: 0.136\n",
            "[10,  4000] loss: 0.163\n",
            "[10,  6000] loss: 0.170\n",
            "[10,  8000] loss: 0.180\n",
            "[10, 10000] loss: 0.205\n",
            "[10, 12000] loss: 0.206\n",
            "[11,  2000] loss: 0.111\n",
            "[11,  4000] loss: 0.110\n",
            "[11,  6000] loss: 0.144\n",
            "[11,  8000] loss: 0.146\n",
            "[11, 10000] loss: 0.171\n",
            "[11, 12000] loss: 0.166\n",
            "[12,  2000] loss: 0.097\n",
            "[12,  4000] loss: 0.123\n",
            "[12,  6000] loss: 0.116\n",
            "[12,  8000] loss: 0.132\n",
            "[12, 10000] loss: 0.133\n",
            "[12, 12000] loss: 0.152\n",
            "[13,  2000] loss: 0.077\n",
            "[13,  4000] loss: 0.100\n",
            "[13,  6000] loss: 0.106\n",
            "[13,  8000] loss: 0.105\n",
            "[13, 10000] loss: 0.130\n",
            "[13, 12000] loss: 0.126\n",
            "[14,  2000] loss: 0.065\n",
            "[14,  4000] loss: 0.075\n",
            "[14,  6000] loss: 0.086\n",
            "[14,  8000] loss: 0.108\n",
            "[14, 10000] loss: 0.119\n",
            "[14, 12000] loss: 0.096\n",
            "[15,  2000] loss: 0.067\n",
            "[15,  4000] loss: 0.066\n",
            "[15,  6000] loss: 0.080\n",
            "[15,  8000] loss: 0.082\n",
            "[15, 10000] loss: 0.105\n",
            "[15, 12000] loss: 0.101\n",
            "[16,  2000] loss: 0.061\n",
            "[16,  4000] loss: 0.057\n",
            "[16,  6000] loss: 0.058\n",
            "[16,  8000] loss: 0.085\n",
            "[16, 10000] loss: 0.071\n",
            "[16, 12000] loss: 0.098\n",
            "[17,  2000] loss: 0.036\n",
            "[17,  4000] loss: 0.083\n",
            "[17,  6000] loss: 0.081\n",
            "[17,  8000] loss: 0.079\n",
            "[17, 10000] loss: 0.106\n",
            "[17, 12000] loss: 0.103\n",
            "[18,  2000] loss: 0.059\n",
            "[18,  4000] loss: 0.058\n",
            "[18,  6000] loss: 0.064\n",
            "[18,  8000] loss: 0.058\n",
            "[18, 10000] loss: 0.073\n",
            "[18, 12000] loss: 0.078\n",
            "[19,  2000] loss: 0.048\n",
            "[19,  4000] loss: 0.062\n",
            "[19,  6000] loss: 0.047\n",
            "[19,  8000] loss: 0.049\n",
            "[19, 10000] loss: 0.068\n",
            "[19, 12000] loss: 0.062\n",
            "[20,  2000] loss: 0.059\n",
            "[20,  4000] loss: 0.065\n",
            "[20,  6000] loss: 0.054\n",
            "[20,  8000] loss: 0.058\n",
            "[20, 10000] loss: 0.062\n",
            "[20, 12000] loss: 0.063\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Probar la red en el conjunto de prueba:\n",
        "\n",
        "Una vez entrenada, es importante evaluar cómo se desempeña la red en datos que no ha visto durante el entrenamiento (conjunto de prueba).  Calculamos la precisión en el conjunto de prueba."
      ],
      "metadata": {
        "id": "yg0kxuKgsSfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# No necesitamos calcular gradientes durante la prueba, así que usamos no_grad() para optimizar\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1) # Obtener la clase predicha (la de mayor probabilidad)\n",
        "        total += labels.size(0)           # Contar el número total de imágenes\n",
        "        correct += (predicted == labels).sum().item() # Contar cuántas predicciones fueron correctas\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qEt8IFosLPF",
        "outputId": "7cf9d658-f917-4463-dc7e-1b92f34e1c63"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 74 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_SAVE_PATH = '/content/mymodelavanzedobjetc_pytorch.pth' # Change file extension to .pth for PyTorch models\n",
        "torch.save(net, MODEL_SAVE_PATH) # Save the state dictionary of your PyTorch model\n",
        "print(f\"Modelo guardado en formato PyTorch en: {MODEL_SAVE_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNJ9Ao9eUX4y",
        "outputId": "1e1a908b-78c2-44ad-8568-dab7d6813350"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo guardado en formato PyTorch en: /content/mymodelavanzedobjetc_pytorch.pth\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}